# -*- mode: Snakemake -*-
#
# Viral contig annotation.
#
# See Readme.md

import csv
from collections import Counter
from pathlib import Path

from Bio import SeqIO
from sunbeam import circular

rule filter_fasta:
    """Filter contigs by size."""
    
    input:
        str(ASSEMBLY_FP/'{sample}_assembly'/'minimo-contigs.fa')
    output:
        fp = str(ANNOTATION_FP/'filtered'/'{sample}_filtered_contigs.fa')
    run:
        n_contigs = 0
        n_kept = 0
        with open(output.fp, 'w') as out:
            for record in SeqIO.parse(input[0], 'fasta'):
                n_contigs += 1
                if len(record) >= Cfg['annotation']['min_contig_len']:
                    n_kept += 1
                    SeqIO.write(record, out, 'fasta')
        results = "%s: %d of %d contigs kept" % (wildcards.sample, n_kept, n_contigs)
        print(results)

rule aggregate_results:
    input:
        contigs=str(ANNOTATION_FP/'filtered'/'{sample}_filtered_contigs.fa'),
        contig_results=expand(
            str(ANNOTATION_FP/'blastn'/'{db}'/'contig'/'{{sample}}.xml'),
            db=Blastdbs['nucl']),
        gene_results=expand(
            str(ANNOTATION_FP/'{blastpx}'/'{db}'/'{orf_finder}'/'{{sample}}.xml'),
            blastpx=['blastp','blastx'],
            db=Blastdbs['prot'],
            orf_finder=['mga'])
    output:
        str(ANNOTATION_FP/'summary'/'{sample}.tsv')
    params:
        dbs=list(Blastdbs['nucl'].keys()) + list(Blastdbs['prot'].keys())
    run:
        contigs = {r.id: r.seq for r in SeqIO.parse(input.contigs, 'fasta')}
        # Separate each set of result files by the database it was blasted against
        contig_results = {
            db: blast_contig_summary(f for f in input.contig_results if db in f)
            for db in Blastdbs['nucl']
        }
        # We only care about the number of hits for the protein database
        gene_hits = {
            db: blast_hits(f for f in input.gene_results if db in f)
            for db in Blastdbs['prot']
        }
        with open(output[0], 'w') as out:
            writer = csv.DictWriter(
                out,
                fieldnames=['sample', 'contig', 'length', 'circular'] + params.dbs,
                delimiter='\t')
            writer.writeheader()
            for contig, contig_seq in contigs.items():
                is_circular = circular(
                    contig_seq,
                    Cfg['annotation']['circular_kmin'],
                    Cfg['annotation']['circular_kmax'],
                    Cfg['annotation']['circular_min_len'])
                results = {
                    'sample':wildcards.sample,
                    'contig':contig,
                    'length':len(contig_seq),
                    'circular':is_circular
                }
                for db in Blastdbs['nucl']:                
                    results[db] = contig_results[db].get(contig, "NA")
                for db in Blastdbs['prot']:
                    results[db] = gene_hits[db].get(contig, 0)
                writer.writerow(results)

rule aggregate_all:
    input:
        expand(
            str(ANNOTATION_FP/'summary'/'{sample}.tsv'),
            sample=Samples.keys())
    output:
        str(ANNOTATION_FP/'all_samples.tsv')
    run:
        with open(output[0], 'w') as out:
            out.writelines(open(input[0]).readlines())
            for infile in input[1:]:
                out.writelines(l for i,l in enumerate(open(infile)) if i > 0)
                
rule _test_aggregate:
    input:
        expand(
            str(ANNOTATION_FP/'summary'/'{sample}.tsv'),
            sample=Samples.keys())
